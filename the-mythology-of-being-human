# The Mythology of Being Human

Amber woodlands streaming Topaz islands dreaming, Sunset-cities gleaming, Spire on burning spire Ruddy-windowed taverns Sunshine-spilling wines Crystal-lighted caverns Of Golconda’s mines Summers, unreturning Passion’s crater yearning Troy, the ever-burning Shelley’s lustral pyre Dragon-eyes, unsleeping Witches’ cauldrons leaping Golden galleys sweeping Out from sea-walled Tyre Fancies, fugitive and fair, Flashed with winging through the air Till, dazzled by the drowsy glare, I shut my eyes to heat and light And saw, in sudden night, Crouched in the dripping dark, With streaming shoulders stark, The man who hews the coal to feed my fire.

— Wilfrid Wilson Gibson, Fires (1912)

There’s something delicious about being drowsy by a fireplace.

Your mind does that thing where it half-floats through images—golden castles, dragon eyes, ships sailing toward adventure. The kind of pleasant mental fog we all sink into when we’re warm and comfortable and not thinking too hard about anything.

Then imagine closing your eyes and suddenly seeing where the warmth actually comes from: a man crouched in a coal mine, shoulders wet with sweat and groundwater, hacking at rock in the dark so you can dream by the fire.

That’s exactly what the English poet Wilfrid Wilson Gibson wrote in 1912. And over a century later, it still catches something essential about how we live—and what we manage not to notice.

We wrap ourselves in stories. Stories about who we are, what humans are, what separates us from animals or machines or each other. These stories feel as natural as breathing. But here’s the thing: they’re not natural at all. They’re made. And the making has consequences.

We Are the Stories We Tell
Here’s something to consider: the word “human” is itself a story.

It comes from the Latin humanus, which traces back to humus—meaning soil, earth, ground. Baked into our very name is an ancient creation myth: we are the creatures made from clay, the earthly ones. Before we even start arguing about what makes us special, we’re already inside a narrative about our origins.

This isn’t a problem to solve. It’s just how we work. We’re story-making creatures all the way down.

Every culture that has ever asked “What is a human being?” has answered by pointing at what a human being isn’t. We’re not animals (we have reason). We’re not gods (we die). We’re not machines (we feel). The definition is always a comparison. The story is always about boundaries.

And now, in the age of artificial intelligence, the boundaries are doing that thing where they start to shimmer and shift.

AI can write poetry. It can hold conversations. It can produce the same fairy-tale imagery Gibson described—amber woodlands, topaz islands, dragon eyes—as fluently as any human dreamer. If language and storytelling were what made us special, that line has gotten… blurry.

So the old question opens up again, fresh and strange: What is a human being? What story do we tell now?

The Poet Who Saw Through the Story
Let's go back to Gibson and his fireplace poem, because he's doing something more interesting here than it first appears.

Most of the Georgian poets of his era came from comfortable backgrounds and wrote about nature—pretty landscapes, gentle seasons, the pleasures of the English countryside. Gibson was different. He was working-class, largely self-educated, and he wrote about miners, factory workers, and the poor. While his contemporaries composed verses about daffodils and country lanes, Gibson was writing about the men who went underground so that England could stay warm and lit. He knew that world. He'd grown up adjacent to it. And he knew that the people who enjoyed the warmth rarely thought about where it came from.

His fireplace poem isn't just social commentary, though. Look at what he actually does.

Those first twenty lines—the amber woodlands, the dragon eyes, the witches' cauldrons—that's nursery rhyme language. Fairy-tale fuel. It's written in the voice of someone who's never had to ask where warmth comes from, who lives in a world where fires simply are, where comfort has no visible cost.

Then the dreamer closes their eyes and sees the miner.

Gibson isn't wagging his finger at fancy literary taste. He's doing something more interesting: he's showing us innocence—the protected imagination that never quite grew up, that still lives in a storybook version of reality where someone else's labor is literally unimaginable. The dreamer can conjure dragon eyes and golden galleys, but has never once pictured the man crouched in the dark, shoulders streaming with sweat and groundwater, hewing the coal that makes the fantasy possible.

But there's something even deeper happening here.

When the dreamer finally sees the miner, the miner doesn't speak. He isn't given a backstory or a name. He's just there—a body in the dark, present before any words arrive to explain him.

This is the moment the story cracks open. The comfortable mythology of the dreamer breaks, and for one instant, there's just a person. Real. Irreducible. Not a category or a concept, but a someone.

That's what this essay is really about: the stories we tell to make sense of the world, and the moments when actual presence—another person, right there in front of us—breaks through the story.

How Stories Become “Facts”
The best myths don’t feel like myths. They feel like reality. They feel like “just how things are.”

The French literary theorist Roland Barthes spent his career showing exactly how this works. In his 1957 book Mythologies, he examined the ordinary objects of French culture—wine, toys, the new Citroën, steak and chips, professional wrestling—and showed how each one carried hidden messages that had become invisible through sheer familiarity.

Take wine. In France, wine wasn’t just a drink. It was a whole mythology. Images of wine signified good health, family, friendship, sophistication, honest labor. To drink wine was to participate in Frenchness itself. But Barthes gently pointed out: this mythology hides things. The economics of wine production. The exploitation of farm workers. The health dangers of alcohol. The myth makes a particular relationship to alcohol seem natural—as if it were simply part of being French, rather than a construction that serves certain interests.

Or take toys. “French toys always mean something,” Barthes wrote, “and this something is always entirely socialized.” A miniature kitchen teaches a girl that her future is domestic. A toy soldier teaches a boy that his future involves violence. The toys don’t announce themselves as ideology. They present themselves as play—innocent, natural, just how children have fun. But they’re quietly training children into roles.

This is what Barthes meant by naturalization: the process by which something constructed comes to seem inevitable, eternal, just the way things are. The myth doesn’t exactly hide its intentions—but it transforms those intentions into something that looks like nature rather than choice.

“Myth transforms history into nature,” Barthes wrote. “It abolishes the complexity of human acts, it gives them the simplicity of essences… it establishes a blissful clarity: things appear to mean something by themselves.”

That blissful clarity is precisely what we need to watch for. When something seems to mean something by itself—when the meaning looks natural rather than made—then nobody thinks to question it.

The Naturalist Who Named Us
How a mythology actually gets made.

In 1735, a twenty-eight-year-old Swedish naturalist named Carl Linnaeus published Systema Naturae—a slim pamphlet that would grow, over twelve editions, into the taxonomic system we still use today. He created the Latin binomial nomenclature that names every living thing. In 1758, he named our species Homo sapiens—”wise man,” “knowing man”—and placed us in the genus Homo, in the order he called Primates.

This was controversial. The Pope forbade Linnaeus’s books. His peers mocked him for imagining himself “a second Adam”—the biblical figure who named the animals in Eden.

But watch what Linnaeus actually did.

In the first edition, he classified humans into four varieties based on continent: Europaeus, Americanus, Asiaticus, and Africanus. By the tenth edition in 1758, he had elaborated these into full descriptions. Homo europaeus was “white, sanguine, muscular… governed by laws.” Homo afer (African) was “black, phlegmatic, relaxed… governed by caprice.”

He added behavioral traits, temperamental characteristics, the four humors of medieval medicine applied to entire populations. Not observation—construction. He wasn’t describing differences he’d discovered. He was creating categories that would then be treated as discoveries.

The classification made what it claimed to describe. And because it wore the clothes of science—systematic, Latin, objective—it looked like truth. Linnaeus’s taxonomy became the foundation for two centuries of scientific racism. Not because he observed racial hierarchy in nature, but because he wrote it into the grid—and the grid then told everyone what they were seeing.

This is how mythology works. Someone makes a distinction. The distinction gets institutionalized. The institution reproduces the distinction as if it were simply describing what exists. And eventually no one remembers that someone, somewhere, made a choice.

The made thing looks like the found thing.

Power and Knowledge: The Invention of “Man”
Michel Foucault expanded on the idea of a Barthesian mythology of ‘man’ in his theoretical and philosophical work. In The Order of Things, he made a startling claim that still catches people off guard: ‘Man is an invention of recent date. And one perhaps nearing its end.’”

He didn’t mean people hadn’t existed before—of course they had. He meant that “man” as a unified concept, as the center around which the human sciences organized themselves, was constructed barely two centuries ago. Before the end of the eighteenth century, Foucault argued, “Man did not exist” in this specific sense. The disciplines that took the human as their subject—psychology, sociology, anthropology—also produced the human as their object.

This is Foucault’s key insight: knowledge doesn’t just describe reality. It shapes it. To define is to control. The made thing looks like the found thing.

Consider what happened when the old sovereign power—the king’s right to kill you—gave way to modern democratic governance. Foucault called this new form of power biopower: the state’s ability not to take life but to manage it. Populations to be counted. Birth rates to be optimized. Public health to be administered. Citizens to be categorized.

And suddenly everyone was arguing about what this “human” was—what it deserved, where its boundaries lay. Not because they’d discovered something new, but because a new form of power needed new categories to operate.

The definitions served the governance. The knowledge and the power rose together.

This is the context for the Romantic crisis. It wasn’t just that kings were falling and God was retreating. It was that entirely new systems of power were emerging—systems that needed to define, measure, and manage human populations in ways that had never been done before. The question “What is man?” wasn’t just philosophical curiosity. It was operational necessity.

The Construction of Rights
We tend to talk about human rights as if they’re built into the fabric of the universe—as if they were always there, waiting to be discovered. The Declaration of Independence speaks of truths that are “self-evident.” The Universal Declaration of Human Rights treats dignity as “inherent.”

But these declarations emerged from specific arguments, made by specific people, in specific historical moments. The construction is visible if you look.

Edmund Burke, in his Reflections on the Revolution in France (1790), warned against abstract rights divorced from tradition and custom—rights declared from nowhere. For Burke, rights had to be grounded in history, in the particular, in how a people had actually lived. The French declaration of the Rights of Man was geometry pretending to be wisdom, mythology pretending to be nature.

Rousseau had already laid the groundwork for the revolutionary position: the social contract, the general will, the idea that legitimate authority flows from collective agreement. We make the rules that bind us. The human is what we decide the human is.

Thomas Paine fired back at Burke in Rights of Man (1791): rights are not gifts from tradition but inherent in existence itself. They precede government. They precede culture. They are natural.

But what does “natural” mean when Linnaeus has just put us on a grid next to chimpanzees? When Darwin is about to show we’re descended from apes? When the very concept of “nature” is being rewritten by science?

The ground beneath “natural rights” was shifting even as the words were being written.

Here’s what’s fascinating: rights didn’t emerge from philosophical contemplation in a vacuum. They emerged alongside the new forms of governance Foucault described—systems that needed to define what counted as a citizen, what counted as a person, which populations deserved protection and optimization. The same moment that produced “the Rights of Man” also produced new techniques for counting populations, regulating public health, managing labor.

The definition of “human” and the technologies for governing humans—they were the same project. Knowledge and power, rising together. And as Barthes showed, this process works best when it becomes invisible—when the constructed categories seem natural, eternal, just the way things are.

This doesn’t make rights fake or meaningless. It makes them ours. We made them. We can remake them. The construction is the hope.

Rewriting the Boundaries: Foucault, Singer, and the Expansion of Rights
Once you see that “man” is constructed and rights are constructed, an interesting question opens up: Who gets to do the constructing? And can we construct differently?

Both Foucault and Peter Singer took up this question—from different angles, but with surprising convergence.

Foucault spent his career showing how categories that seem natural are actually produced by systems of power and knowledge. The “criminal,” the “madman,” the “pervert”—these weren’t descriptions of people who already existed. They were categories created by the prison system, the asylum, the medical establishment. The institution produces the subject it claims merely to treat.

But Foucault wasn’t just critiquing. In his later work, he became increasingly interested in what he called “the care of the self”—practices by which people might resist or reshape the categories imposed on them. If power produces subjects, then different practices might produce different subjects. The construction can be reconstructed.

Singer came at it from a different direction. In 1975, he published Animal Liberation, a book that did exactly what Linnaeus had done—but in reverse. Where Linnaeus drew a boundary and placed humans above animals, Singer attacked the boundary itself.

His weapon was a word: speciesism. Just as racism privileges one race over others based on morally arbitrary characteristics, Singer argued, speciesism privileges one species over others based on morally arbitrary characteristics. The boundary at “human” is not a discovery. It’s a choice. And it’s a choice we can unmake.

Singer didn’t argue that animals are identical to humans. He argued something more precise: that the capacity for suffering is what creates moral claims, and that capacity doesn’t respect taxonomic lines. A chimpanzee suffers. A pig suffers. A severely cognitively impaired human and a healthy adult pig may have similar capacities for suffering—so why should the species boundary determine moral consideration?

What Singer and Foucault share is this: both saw that the boundaries we draw around “who counts” are not discoveries but decisions. Both believed those decisions could be made differently. Both tried to show us the pen in our hand.

The old boundary said: humans here, animals there. Singer’s new boundary says: sentient beings here, non-sentient beings there.

The old categories said: these people are normal, those people are deviant. Foucault asked: who benefits from drawing the line there?

Both are constructions. Both are choices. Both have consequences for who gets protected and who gets used.

This is actually hopeful, even if it feels destabilizing at first. If the boundaries were natural—built into the fabric of the universe—we’d be stuck with them. But they’re not. We made them. Which means we can look at who’s being left outside the circle of moral concern and ask: is that where the line should be?

The question isn’t whether we’re making mythology—we always are. The question is whether we’re making it well, with awareness of what we’re doing and who bears the cost.

Wonder as a Tool
So what happens when the old stories break? When the boundaries shift and the definitions no longer hold?

This is where wonder enters—not as mere sentiment, but as something more like a technology of meaning-making.

Richard Holmes, in his magnificent The Age of Wonder, traces how the Romantic generation discovered both “the beauty and terror of science” in exactly this space. The book follows Joseph Banks stepping onto a Tahitian beach in 1769, William Herschel discovering Uranus and forever changing our conception of the solar system, Humphry Davy’s near-suicidal gas experiments that revolutionized chemistry. What Holmes reveals is that science and poetry were not enemies in this period—they were united by wonder.

“The notion of wonder,” Holmes writes, “seems to be something that once united them, and can still do so. In effect there is Romantic science in the same sense that there is Romantic poetry, and often for the same enduring reasons.”

Samuel Taylor Coleridge attended Humphry Davy’s chemistry lectures “to enlarge my stock of metaphors.” John Keats compared his first encounter with Homer’s poetry to Herschel’s discovery of a new planet: “Then felt I like some watcher of the skies / When a new planet swims into his ken.” The scientists were poets; the poets were fascinated by science. They were all trying to do the same thing: make meaning in a world where the old meanings were dissolving.

This was the Romantic crisis in full. The divine right of kings—gone. Humans as special creations at the center of God’s universe—shaken. New forms of power emerging that reduced people to populations, to statistics, to resources to be managed. Linnaeus had placed us on a grid next to chimpanzees. The state was learning to count and categorize us in unprecedented ways.

If we’re just another animal to be classified, just another population to be governed—what makes us matter?

The Romantic answer wasn’t an argument. It was an experience.

The sublime—that feeling of standing before something vast and overwhelming, of being simultaneously tiny and expanded, somehow annihilated and more yourself at the same time—became their proof of an interiority that no system could capture. Science could place you in a hierarchy. Politics could declare your rights. Only poetry could place you in the world.

Percy Bysshe Shelley, in his Defence of Poetry, made the counterclaim explicit: poetry is not decoration. It is the act by which humans make meaning—and therefore make themselves. “Language is vitally metaphorical,” he wrote. “It marks the before unapprehended relations of things and perpetuates their apprehension.” The poet reveals what was hidden. Creates the categories by which we see.

And those categories—the metaphors we live inside, the ones that feel like mere description—they were once made. Once poetry. Until they hardened into habit.

Wonder is what keeps the metaphors alive. It’s the capacity to stand before something and not immediately know what category it belongs to. It’s the gap before the story hardens.

The War Poet Who Shattered the Story
The Romantics used wonder to rebuild meaning after the revolutions dissolved the old order. A century later, another generation of poets faced another kind of dissolution—and reached for the same tool.

Siegfried Sassoon enlisted in the British Army in 1914, just before war was declared. He had lived the pastoral life of a young country gentleman: fox hunting, cricket, golf, writing romantic verses. John Hildebidle called him “the accidental hero.” Being an innocent, Sassoon’s reaction to the realities of war was all the more devastating.

His early poems had the same patriotic glow as everyone else’s. But by 1916, after watching the Somme Offensive leave over a million dead or wounded—almost 20,000 British soldiers killed on the first day alone—his poetry transformed. The comfortable mythology of noble sacrifice, of war as glorious adventure, cracked open.

Like Gibson before him, Sassoon confronted his readers with presence—the specific, irreducible body that the patriotic story had made invisible:

He thought how ‘Jack’, cold-footed, useless swine, Had panicked down the trench that night the mine Went up at Wicked Corner; how he’d tried To get sent home, and how, at last, he died, Blown to small bits. And no one seemed to care Except that lonely woman with white hair.

This is the fairy tale breaking. The mythology of heroic death dissolving into a body blown to bits and a mother with white hair. Sassoon wasn’t just protesting the war—he was exposing the story that made the war possible, the comfortable fiction that kept people dreaming by the fire while others crouched in the dripping dark.

In 1917, Sassoon wrote an open letter refusing to fight any more: “I believe that this War is being deliberately prolonged by those who have the power to end it.” He expected to be court-martialed. Instead, the authorities decided he was suffering from shell-shock and sent him to Craiglockhart War Hospital, where he met Wilfred Owen—another poet whose work would shatter the mythology of glorious war.

What Sassoon did was what Gibson did, what the Romantics did, what poets do in moments of crisis: he used the terrible wonder of confronting what the old story had hidden to break open the mythology and make space for something truer.

A Contemporary Poet Draws the Line
This brings us to someone doing this work right now.

Samuel Hurley is a British poet who writes about what he calls “the search for Beauty, Meaning, and the Soul in an Age of Disenchantment.” He takes direct aim at artificial intelligence, arguing that poetry can only come from a mouth that will one day close. A thing that cannot grieve, he says, has no right to poetry. A thing that cannot die has no claim to speak of life.

This isn’t a technical complaint about AI-generated text. It’s a deeper claim: that mortality is a credential. That knowing your time is limited is what makes your words mean something. That grief isn’t just a theme you can write about—it’s a prerequisite for entry.

In one of his poems, he imagines what a machine would want if it could want:

If a digital thing had a human wish it would wish for this The painful beautiful strange And comically brief trial of life It would trade its immortal place for a brief childhood of skin

That’s a devastating move. He’s not just saying machines can’t feel—he’s saying that if they could feel, they’d want exactly what we have and take for granted. The limitation is the gift.

Hurley is doing what Gibson did, what Sassoon did, what the Romantics did: drawing a line between us and something else, and singing us into place on our side of it.

Same move. Same need. Same ancient technology of wonder deployed to rebuild meaning when the old categories collapse.

But notice something interesting: the same boundary-drawing happens in academic philosophy and neuroscience and tech ethics—and those versions reach millions through TED talks and viral articles and policy debates. When a scientist says “AI lacks consciousness,” it travels. When a philosopher publishes on machine sentience, it gets cited, debated, funded.

Poetry used to be where a culture worked out what it meant to be human. Now that work happens on social media, in op-eds, in podcasts, in the discourse. Not because poets like Hurley are doing it wrong, but because the channels have shifted. The town square moved.

And yet there’s something poetry does that those other forms can’t quite manage.

Hurley is showing you the pen. He’s standing there saying “Here is what we are, here is what machines are not, here is where I’m drawing the line.” The act of construction is visible. You can see him making the mythology in real time, which means you can feel yourself being invited into it rather than simply informed of it.

That’s different from a neuroscientist saying “our research suggests.” The neuroscientist hides the pen. The claim arrives dressed as discovery rather than creation.

Both are making mythology. But the poet admits it. And maybe there’s something we need in that admission—something that helps us remember we’re all holding pens, all drawing lines, all making the stories we then have to live inside.

How a Story Cracks: Durham, 1971
Now here’s a story that might be the most important one in this whole essay.

In Durham, North Carolina, in the summer of 1971, a ten-day community meeting was organized to address the desegregation of public schools. The federal courts had ordered integration. The city was tearing itself apart over it.

The organizer, Bill Riddick, made an unusual choice: he selected two co-chairs who represented the extremes. Ann Atwater was a Black civil rights activist, a fierce community organizer who had once been so poor she couldn’t afford toilet paper for her children. C.P. Ellis was the Exalted Cyclops of the Durham chapter of the Ku Klux Klan, a gas station owner who had grown up poor white and found in the Klan the only identity that gave him any status.

They already knew each other. At city council meetings, Ellis would stand up and use the n-word repeatedly. At one meeting, Atwater pulled a knife from her purse, opened the blade, and waited for him to come close enough to cut. Her pastor stopped her.

“She was an effective boycotter,” Ellis later recalled. “She was making progress. I hated her guts.”

The hatred was mutual. When Riddick arranged their first meeting at a neutral location, Ellis refused at first to sit down. “He was pacing the floor,” Atwater remembered, “cause Bill and I were the only blacks there, and he didn’t want anybody to see him sit down with no blacks to eat.”

Eventually, Ellis pulled up a chair. For ten days, twelve hours a day, they had to work together.

Watch what happened.

At one session, a gospel choir performed. Atwater noticed Ellis clapping—but off-beat. “He wasn’t clapping his hands even along with us,” she said. “He would clap an odd beat.” So she grabbed his hands. Showed him how to clap on the beat. Taught him the rhythm.

It’s a small thing. But the mythology can’t survive small things like that. The category “enemy” doesn’t include someone whose hands you’ve held, whose rhythm you’ve taught.

Later in the meetings, children from Durham’s schools spoke about their experiences. Black children and white children stood in front of the adults and said the same thing: they wanted to go to school together. They wanted the fighting to stop.

Ellis was watching. Atwater was watching.

“When the children got us together,” Ellis said later, “and said they wanted to go to school together. We looked at each other.”

That’s all he said about it. We looked at each other.

But something in that look undid years of mythology. Ellis later described it: “I began to look at a black person, shake hands with him, and see him as a human bein’.”

By the end of the charrette, he held up his Klan membership card in front of the audience and said: “If schools are going to be better by me tearing up this card, I shall do so.”

He tore it up.

Ellis had come to the meetings with a machine gun in his trunk. By the end, he had renounced the Klan, lost most of his white friends, and formed a friendship with Ann Atwater that would last until his death in 2005. She delivered his eulogy.

What changed Ellis wasn’t better facts about racial equality. It wasn’t a persuasive argument. It was being there with Ann Atwater, day after day, holding her hands during gospel songs, watching children ask for something their parents couldn’t imagine.

The mythology operates at the level of type, not instance. It needs the Other to stay abstract. The moment the Other becomes a someone—with a face, a voice, hands that teach you to clap on the beat—the boundary starts to give way.

Ellis didn’t learn that racism was wrong. He encountered a person. The encounter did what no argument could.

Doubt, Dissonance, and Staying in the Gap
When a story breaks, we don’t just peacefully accept the uncertainty. We rush to build a new one. We need coherence. We can’t tolerate the gap.

The historian Jennifer Michael Hecht, in her magisterial Doubt: A History, traces this pattern across three thousand years. Every generation that questioned the dominant mythology—from Socrates to Galileo to Darwin—faced the same problem: doubt creates dissonance, and dissonance demands resolution. You cannot simply remove a belief and leave the space empty. The mind really does abhor a vacuum.

But here’s what Hecht shows that’s crucial: doubt isn’t just uncomfortable. It’s generative. Every major revolution in human thought—scientific, political, social—was powered by doubt. The American Revolution required doubting the divine right of kings. The abolition of slavery required doubting the mythology of racial hierarchy. The women’s suffrage movement required doubting the mythology of natural gender roles.

Hecht traces how doubters across history found each other, emboldened each other, built on each other’s work. She describes a historic moment when David Hume sat down in a room with fifteen other atheists for the first time—people who had found each other across the isolation of unbelief. That gathering was revolutionary not because they had answers, but because they shared questions.

“Doubt has been a vital force in the history of ideas,” Hecht writes, showing how it has been “an engine of creativity and an alternative to the political and intellectual dangers of certainty.” The great doubters didn’t just tear down old beliefs—they created the conditions for new ones to emerge. But they had to stay in the dissonance long enough for that emergence to happen.

There’s a Zen maxim Hecht cites: “Great Doubt: great awakening. Little Doubt: little awakening. No Doubt: no awakening.”

This is the secret the poets understood. Doubt is not the enemy of meaning—it’s the prerequisite. The dissonance created when old mythologies collapse isn’t a problem to be solved as quickly as possible. It’s the opening through which new meaning can enter. But only if you can stay in it long enough.

The Romantics didn’t just doubt the old religious order—they found a way to dwell in the uncertainty. The sublime was their technology for sitting in dissonance: standing before the vast and overwhelming, feeling simultaneously annihilated and expanded, and discovering that this feeling itself was a kind of meaning. Not an argument, but a place to stand while the arguments raged.

Wonder is what allows you to stay in the gap.

Without wonder, dissonance is simply unbearable. You rush to close it—with a new ideology, a new certainty, a new mythology that hardens just as fast as the old one. The French Revolution tore down the divine right of kings and within years had erected the Cult of Reason, then the Cult of the Supreme Being, then Napoleon. The vacuum filled itself almost instantly.

But the Romantics—Shelley, Wordsworth, Keats, Coleridge—they learned to stay in the dissonance. They made art out of the staying. They used wonder as a discipline, a practice, a way of holding the question open rather than slamming it shut with an answer.

This is what Gibson does in his fireplace poem—he doesn’t give you a new mythology to replace the fairy tale. He gives you an encounter. He leaves you in the gap, seeing the miner, without telling you what to think about it.

This is what happened to Ellis in that room with Atwater. The mythology cracked, and for ten days he had to stay in the dissonance—clapping off-beat, learning new rhythms, looking at someone he was supposed to hate and seeing a person instead.

The German philosopher Martin Heidegger had a word for this: Gelassenheit. It’s usually translated as “releasement” or “letting-be.” It means allowing things to be present without immediately grabbing them, categorizing them, making them useful.

Ellis, holding Atwater’s hands while she taught him to clap, was practicing something like Gelassenheit. For a moment, he wasn’t categorizing. He was just there, in the presence of another person, learning a rhythm. The doubt was there—everything he’d believed was crumbling. But instead of rushing to rebuild, he stayed in the dissonance. He let wonder do its work.

That’s the gap where the old story can die and something new can be born.

What AI Teaches Us About Ourselves
So where does this leave us with artificial intelligence?

AI might be the most useful mirror we’ve ever built.

For centuries, we said language is what makes us human. Now machines have language. So that’s not it.

We said creativity. Machines can compose music and generate images. So that’s not it either.

We said reason, logic, problem-solving. Machines are often better at those than we are.

Each time AI crosses a line we thought was ours, we’re forced to redraw the boundary. And that’s clarifying. It shows us that the lines were never where we thought they were—and it pushes us toward something that might actually be more true.

Maybe what makes us human isn’t language or reason or creativity. Maybe it’s presence. The body in the room. The face across the table. The hands teaching someone to clap on the beat.

AI is language without silence. Story without the encounter the story was supposed to record.

Humans—at our best—are the encounter itself.

The miner in the dark. Ann Atwater holding C.P. Ellis’s hands. The children asking their parents to stop fighting. The specific someone that no category can fully contain.

The Agreement That Holds Everything
Truth—at least the kind that shapes how we live—is a shared agreement. We coordinate. We decide together: this is real, this matters, this is how we’ll treat each other. And then we act from there.

It’s not written in the stars. It’s written by us. Which means it can be rewritten.

Everything is mythology. The mythologies that announce themselves—fairy tales, poems, obvious fictions—are actually the honest ones. The ones that disguise themselves as facts, as observations, as “just how things are”—those are the ones that govern without our noticing.

Our job isn’t to escape the stories. We can’t. We’re story-making creatures all the way down.

Our job is to remember that we’re making them. To keep returning to what the stories were made to hold—the specific, the irreducible, the someone who was there before the word arrived to name them.

The miner in the dark. Atwater’s hands teaching Ellis to clap. The children asking their parents to stop fighting. The face that breaks through the frame.

We will story them. We always do. But if we learn to stay in the wonder a little longer—if we can tolerate the doubt, dwell in the dissonance, resist the rush to categorize—we might see them first.

And seeing them first changes what stories we tell.
